{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "#install required libraies in terminal\n",
    "pip install langchain\n",
    "pip install openai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the required libraries\n",
    "import langchain\n",
    "import os\n",
    "\n",
    "#set the environment variables\n",
    "OPENAI_API_TYPE = \"Azure\" #Azure OpenAI API\n",
    "OPENAI_API_VERSION = \"2023-05-15\" #Azure OpenAI API version\n",
    "OPENAI_API_BASE = \"https://xe-ai.openai.azure.com/\" #Azure OpenAI API endpoint\n",
    "OPENAI_API_KEY = \"05263d9bd83a4c0d9bb2c74f1cfbb684\" #Azure OpenAI API key\n",
    "DEPLOYMENT_NAME = \"deploy-gpt-35-turbo\" #Azure OpenAI deployment name\n",
    "\n",
    "#load he environment variables\n",
    "os.environ['OPENAI_API_TYPE'] = OPENAI_API_TYPE\n",
    "os.environ['OPENAI_API_VERSION'] = OPENAI_API_VERSION\n",
    "os.environ['OPENAI_API_BASE'] = OPENAI_API_BASE\n",
    "os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\xaelizon\\Downloads\\GH\\Shell-Power\\.venv\\Lib\\site-packages\\langchain_community\\llms\\openai.py:254: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain_community.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n",
      "c:\\Users\\xaelizon\\Downloads\\GH\\Shell-Power\\.venv\\Lib\\site-packages\\langchain_community\\llms\\openai.py:1075: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain_community.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#import Azure OpenAI and LLM\n",
    "from langchain.llms import AzureOpenAI\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "\n",
    "#create an instance of AzureOpenAI\n",
    "llm = AzureOpenAI(DEPLOYMENT_NAME=\"deploy-gpt-35-turbo\", model_name=\"gpt-3.5-turbo\")\n",
    "\n",
    "template = \"\"\"\n",
    "You are an intelligent supportive assistance . Answer the following question with the best you can. provide only the answer to the question and nothing else.\n",
    "Question: {question}\n",
    "Answer:\"\"\"\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n",
    "\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import error\n",
    "#Language generation, #creative example\n",
    "question = \"create a tag line for a coffee shop\"\n",
    "print(llm_chain.run(question))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "# Assuming 'question' is a string containing the user's question\n",
    "question = \"What is the capital of France?\"\n",
    "\n",
    "response = openai.Completion.create(\n",
    "    engine=\"text-davinci-003\",\n",
    "    prompt=question,\n",
    "    max_tokens=100,\n",
    "    n=1,\n",
    "    stop=None,\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "print(response.choices[0].text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2204648705.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[63], line 3\u001b[1;36m\u001b[0m\n\u001b[1;33m    pip install pypdf\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#Document QnA Example    \n",
    "## installing Libraries\n",
    "pip install pypdf\n",
    "pip install tiktoken\n",
    "pip install chromadb\n",
    "pip install sentence_transformers\n",
    "\n",
    "\n",
    "#import libraries \n",
    "from langchain.document_loaders import PDFLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import ChromaDB\n",
    "from langchain.chains import VectorDBQA\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "#load the document\n",
    "loader = PyPDFLoader(\"Australia-Wikipedia.pdf\")\n",
    "pages = loader.load_and_split()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "docs = text_splitter.split_documents(pages)\n",
    "\n",
    "#build vector db\n",
    "embeddings = OpenAIEmbeddings(engine=\"text-embedding-ada-002\")\n",
    "db = ChromaDB.from_documents(docs, embeddings)\n",
    "\n",
    "#build qa db\n",
    "qa = VectorDBQA.from_chain_type(llm=llm, chain_type=\"stuff\", vectorstore=db)\n",
    "\n",
    "#build q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Where does the name Australia come from?\"\n",
    "qa.run(query) \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "csharp",
    "items": [
     {
      "aliases": [],
      "name": "csharp"
     }
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
